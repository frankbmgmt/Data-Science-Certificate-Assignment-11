---
title: "Assignment 11"
author: "Frank Bonifazi"
date: "6/26/2019"
output: html_document
---

```{r}
install.packages('tidyverse')
install.packages('modelr')
install.packages('titanic')
install.packages('caret')


```


```{r}
library('tidyverse')
library('caret')
library('modelr')
library('titanic')

options(na.action = na.warn)
```

# The Titanic Data

```{r}
# Load the data
data("titanic_train") # training
all_data = titanic_train %>% 
  as_tibble() %>%
  mutate(Survived = factor(Survived)) # this is binary yes/no 0/1
```
#FB: I checked - Survived is now a factor data-type

## Determine what's worth analyzing

We are going to try and predict `Survived`

```{r}
head(all_data)
```

#FB: 12 variables

```{r}
all_data %>%
  colnames()
```



```{r}
all_data %>% summary()
```


#FB: Only NAs are ONLY in the Age column....177

```{r}
all_data %>% glimpse()
```

#FB: glimpse is a nice way to see the variable, the data-types and SOME OF THE VALUES. Is there a way to scroll to the right? 

## What is the following function doing?
< Answer Here >
```{r}
colSums(all_data == '')
```


#FB: This is checking for no data (not, NULL or NA).

# Cabin assignment is high at 687
# Embarked (Where they started on the ship) = 2

```{r}
colsums_spaces = function(table_name){
  results = colSums(table_name == "")
  return(results)
}
```

```{r}
colSums(all_data == '')
```


## How should we handle missing values?
Looking at `Embarked`
```{r}
all_data %>% group_by(Embarked) %>% count()
```

#FB: If it was in the assignment, I'd check for a similar fare to map the 2 missing Embarked.

## For learning purposes impute the following values:
  - Missing `Embarked` values should be `S`
  - Missing and `NA` values for `Age` should be replaced by the median `Age` 
  - `NA` values for `Fare` should be replaced by the mean `Fare` 

< Answer with code below >
```{r}
all_data = titanic_train %>% 
  as_tibble() %>%
  mutate(Embarked_New = Embarked) %>%
filter(Embarked_New == "")
head(all_data) # Works!

```

```{r}
all_data_new = titanic_train %>% 
  as_tibble() %>%
  mutate(Embarked_New = Embarked) %>% 
mutate(Embarked_New=replace(Embarked_New, Embarked_New=="", "S"))
 #Works! Now for the other variables...

```



```{r}
all_data_new = all_data_new %>% 
  as_tibble() %>%
  mutate(Age_New = Age) %>%
   
  mutate(Age_New = replace_na(Age_New, 0)) %>%
mutate(Age_new = replace(Age_New, Age_New==0, mean(Age_New)))
  view(all_data_new)
  #Works! 
```


```{r}
all_data_new = all_data_new %>% 
  as_tibble() %>%
  mutate(Fare_New = Fare) %>%
   
  mutate(Fare_New = replace_na(Fare_New, 0)) %>%
mutate(Fare_new = replace(Fare_New, Fare_New==0, mean(Fare_New)))
  view(all_data_new)
  #Works but did NOTHING!  There are no NAs in Fare column!
```


## Prepare data to train a model
Why should we drop `PassengerId, Ticket, Name, Cabin` from our data?
< Because they don't add any insight into who survived... unless there's someone
really important who got special treatment like 1st safety boats>


< Answer in code below>
```{r}
all_data_new = all_data_new #%>%
  head(all_data_new)
  #select() #%>% # Add your code within select

```


Separate the data into test and train, call the new data (which has the imputed values) `train_data` and `test_data` to distinguish them from the raw data. Take the first 80% of rows as train and the last 20% of rows as test.
< Answer in code Below >
```{r}
train_split = .8
max_train_rows = round(train_split * nrow(all_data_new))

starting_test_row = max_train_rows + 1

train_data = all_data_new[1:max_train_rows,]

test_data = all_data_new[starting_test_row:nrow(all_data_new),]


```

## What is wrong with the method above?
<It's not random at all.  I could assume that the passenger ID increases as tickets are sold. >

## Build and train a model
Build a logistic regression by using the `glm` function (the family parameter as `family = binomial(link = "logit")`). Show a `summary()` of your model.

#FB: Example
fit <- glm(count ~ x1+x2+x3, data=mydata, family=poisson())
summary(fit) display results

< Answer with code below >

#FB: Let's look at some plots 1st!

```{r}
train_data %>%
ggplot(aes(x=Age_new, y=Survived)) +
geom_point()

```


```{r}
train_data %>%
ggplot(aes(x=Pclass, y=Survived)) +
geom_point()

```

```{r}
train_data %>%
ggplot(aes(x=Sex, y=Survived)) +
geom_point()

```
```{r}
library(ggplot2)
ggplot(continuous, aes(x = Age)) +
    geom_density(alpha = .2, fill = "#FF6666")
```

```{r}
train_data %>%
 
glm(Survived ~ Age_new, data = . ,family = binomial(link = "logit")) %>%
  
summary()
```

```{r}
train_data %>%
 
glm(Survived ~ Pclass, data = . ,family = binomial(link = "logit")) %>%
summary()
```

```{r}
train_data %>%
 
glm(Survived ~ Sex, data = . ,family = binomial(link = "logit")) %>%
summary()
```

### Is there anything interesting in your model?
< The p-values are very small for Pclass and Sex - worth persuing. >

On your `train_data` -- `add_predictions()` requires a `type` parameter. Use `type = 'response'` and create predictions.
<Answer with code below>
```{r}
#train_data %>%
  
  model1 <- glm(formula = Survived ~ Pclass, data = train_data, family=binomial(link = "logit"))


  add_predictions(train_data, model1, var = "Pclass", type = "response") #%>%
    #summary()
  
#add_predictions() # Add your code within add_predictions()
```

How do you interpret the predictions from your model?
<I don't know how to inperpret this....but, Pclass is now a numeric of decimal values. Let's plot it.>


```{r}
#train_data %>%
   model1 <- glm(formula = Survived ~ Pclass, data = train_data, family=binomial(link = "logit"))

  add_predictions(train_data, model1, var = "Pclass", type = "response")
  
ggplot(train_data, aes(x=Pclass, y=Survived)) +
geom_point()

```
#FB: How come it's not a poisson shapE?

Create predictions for your `test_data` using the same method as above. Call your new tibble `results`
```{r}
results = test_data %>%
  add_predictions() # Add your code within add_predictions()
results
```

```{r}
results = test_data %>%
  
 model2 <- glm(formula = Survived ~ Pclass, data = results, family=binomial(link = "logit"))
  
add_predictions(results, model2, var = "Pclass", type = "response")
```

With your new test_data Set a cutoff point at `>= 0.6` for `Survived` to be `1` to replace `pred`
```{r}
results = results %>%
  mutate() # Add your code within mutate (hint, if_else and factor will be important functions)
```


Use the library `caret` to create a confusion matrix `confusionMatrix()` and describe the output.
```{r}
confusionMatrix() # Add your code here
```


## Major issues

We did not look at the balance of `Survived` (0 or 1). Why is this important?  

< Answer Here >

We built one model based off of the `titanic_train` data. Why should we have fit more?

< Answer Here >